{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Notes.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMCKG+ntdBldfrE2uHGgIjN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# NOTES"],"metadata":{"id":"lkbGEfyZQWVb"}},{"cell_type":"markdown","source":["## Percentile :- <br>\n","###Definition 1:\n","For percentile p, p % elements should be <= to the element selected as percentile p. <br>\n","Formula: \n","The normal formula being that percentile is at (p/100)*(n + 1)/index. Intuition behind it:- \n","1. For odd n, p(n + 1) is necessary. Eg. For n = 11(elements = 1:11), using pn, 50 percentile is 5.5, which can't be correct as only 5 elements < 5.5 from elements 1:11 are less than 50%.\n","Hence, we use n+1 for this. Now, 50% percentile = 6. And now, 6 elements are <= 6 which is > 5.5. So, it avoids undercounting.\n","2. For n - even, the above problem doesn't arise. Eg. for elements = 1:12, 50%tile is 6, which is in line with the above definition. <br>\n","However, there is asymmetry. 25%tile is 3, 3rd element from the left. However, 75%tile, which one would think be 3rd element from the right, is actually 4th element from the right. Hence, to enforce symmetry, we can use p(n + 1).\n","Now, 25%tile is 3.25 and 75%tile is 9.75. Now, both of these are at a distance of 2.25 from their respective ends.\n","\n","###Definition 2, 3: <br> \n","Can look in notes\n","\n","All these different methods give different results."],"metadata":{"id":"48PaqtmtQbGS"}},{"cell_type":"markdown","source":["## Measures of Spread <br>\n","\n","Variance is preferred over sum of absolute deviations because firstly, mathematics around variance is easier like smoothness and differentiability, and secondly, squaring the deviation highlights the outliers.<br>\n","However, as squaring values also squares the units and also, sum of squared deviations is less interpretable in the context of the normal unsquared data, hence taking a square root of the final value ensures unit correctness and also the new value is comparable to the original unsquared data."],"metadata":{"id":"kS2pIEXpqTZW"}},{"cell_type":"markdown","source":["# Inter-quartile range = Q3-Q1\n","Is better than normal range as this doesn't get affected by outliers, whereas the usual range does. \n","So this is just like a small adjustment to take care of outliers."],"metadata":{"id":"DCb0jU-pfseA"}},{"cell_type":"markdown","source":["## Standardising data using mean and variance.\n","\n","Say we have 2 set marks, one out of 1000 and one out of 120.<br>\n","We can't compare students from the two tests directly, we need some method to introduce some sort of sameness in both the data sets. <br>\n","Intuitively, what I would do is subtract min. value and then divide by maxV - minV. This would give a data set ranging from 0 to 1. Now in both data sets, min. and max. values are equal, 0 and 1. However, it could so happen that in test1 min/max score was 490/500 and in the other it was 1/119.<br> But this way could again lead to one data set being concentrated near 0 and other near 1, which again doesn't solve our problem.<br>\n","Hence, what can be done instead is make their means common, for which we can simply subtract their respective means from the data. So what we're saying now is that let the level of the avg. student in both the tests be same.\n","But still, the units of the two would be totally different. Also, a 100 on 2nd scale is much smaller than 100 on the other scale.\n","How to make these two comparable?<br>\n","What we can do is not compare 100 directly, but the corresponding percentages of some value from the distribution itself. We could use the range/max. for percentage. But, statistically, using s.d. is the norm.<br>\n","Dividing by S.D. makes the spread of the whole distribution 1. \n","So now, we can say that both distributions are on avg. 0, and are spread the same. The internal relationships between values would still be retained. And hence, now the two data sets are comparable.\n","<br>\n","We say that if a student scored 2 s.d. above mean in test1, and the other scored 5 s.d. in test2, the 2nd student would be better. This is not an absolute method. In this example, simply taking % of the total marks might be fulfilling, however, it doesn't take into account the relative difficulty of the tests, which is neutralized only when we subtract the mean from all the values.<br>\n","Note:- this method isn't absolute, there are other methods as well.<br>\n","This would become more intuitive later, like in ML.\n","The mean and S.D. of the standardized data is 0 and 1 respectively.(mental clc)\n"],"metadata":{"id":"z-KqEXNVqSQ_"}},{"cell_type":"markdown","source":["# Formal Definition of outliers:-\n","Points which are < Q1 - 1.5(Q.R.) or > Q3 - 1.5(Q.R.), where Q.R. = Q3-Q1(Quartile Range) <br>\n","Would obviously not work always, but is good to know as a measure"],"metadata":{"id":"9BjMCdLrfdiz"}},{"cell_type":"code","source":[""],"metadata":{"id":"1xji5SQ_V7wp"},"execution_count":null,"outputs":[]}]}